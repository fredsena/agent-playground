"""
Multi-Source Knowledge Router Example

This example demonstrates the router pattern for multi-agent systems.
A router classifies queries, routes them to specialized agents in parallel,
and synthesizes results into a combined response.
"""

import operator
from typing import Annotated, Literal, TypedDict

from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from pydantic import BaseModel, Field
from utils.llm import get_llm
from pprint import pprint


# State definitions
class AgentInput(TypedDict):
    """Simple input state for each subagent."""
    query: str


class AgentOutput(TypedDict):
    """Output from each subagent."""
    source: str
    result: str


class Classification(TypedDict):
    """A single routing decision: which agent to call with what query."""
    source: Literal["github", "notion", "slack"]
    query: str


class RouterState(TypedDict):
    query: str
    classifications: list[Classification]
    results: Annotated[list[AgentOutput], operator.add]
    final_answer: str


# Structured output schema for classifier
class ClassificationResult(BaseModel):
    """Result of classifying a user query into agent-specific sub-questions."""
    classifications: list[Classification] = Field(
        description="List of agents to invoke with their targeted sub-questions"
    )


# Tools
@tool
def search_code(query: str, repo: str = "main") -> str:
    """Search code in GitHub repositories."""
    return f"Found code matching '{query}' in {repo}: authentication middleware in src/auth.py"


@tool
def search_issues(query: str) -> str:
    """Search GitHub issues and pull requests."""
    return f"Found 3 issues matching '{query}': #142 (API auth docs), #89 (OAuth flow), #203 (token refresh)"


@tool
def search_prs(query: str) -> str:
    """Search pull requests for implementation details."""
    return f"PR #156 added JWT authentication, PR #178 updated OAuth scopes"


@tool
def search_notion(query: str) -> str:
    """Search Notion workspace for documentation."""
    return f"Found documentation: 'API Authentication Guide' - covers OAuth2 flow, API keys, and JWT tokens"


@tool
def get_page(page_id: str) -> str:
    """Get a specific Notion page by ID."""
    return f"Page content: Step-by-step authentication setup instructions"


@tool
def search_slack(query: str) -> str:
    """Search Slack messages and threads."""
    return f"Found discussion in #engineering: 'Use Bearer tokens for API auth, see docs for refresh flow'"


@tool
def get_thread(thread_id: str) -> str:
    """Get a specific Slack thread."""
    return f"Thread discusses best practices for API key rotation"


# Models and agents

llm = get_llm()

model = llm
router_llm = llm

github_agent = create_agent(
    model,
    tools=[search_code, search_issues, search_prs],
    system_prompt=(
        "You are a GitHub expert. Answer questions about code, "
        "API references, and implementation details by searching "
        "repositories, issues, and pull requests."
    ),
)

notion_agent = create_agent(
    model,
    tools=[search_notion, get_page],
    system_prompt=(
        "You are a Notion expert. Answer questions about internal "
        "processes, policies, and team documentation by searching "
        "the organization's Notion workspace."
    ),
)

slack_agent = create_agent(
    model,
    tools=[search_slack, get_thread],
    system_prompt=(
        "You are a Slack expert. Answer questions by searching "
        "relevant threads and discussions where team members have "
        "shared knowledge and solutions."
    ),
)


# Workflow nodes
def classify_query(state: RouterState) -> dict:
    """Classify query and determine which agents to invoke."""
    structured_llm = router_llm.with_structured_output(ClassificationResult)

    result = structured_llm.invoke([
        {
            "role": "system",
            "content": """Analyze this query and determine which knowledge bases to consult.
For each relevant source, generate a targeted sub-question optimized for that source.

Available sources:
- github: Code, API references, implementation details, issues, pull requests
- notion: Internal documentation, processes, policies, team wikis
- slack: Team discussions, informal knowledge sharing, recent conversations

Return ONLY the sources that are relevant to the query."""
        },
        {"role": "user", "content": state["query"]}
    ])

    return {"classifications": result.classifications}


def route_to_agents(state: RouterState) -> list[Send]:
    """Fan out to agents based on classifications."""
    return [
        Send(c["source"], {"query": c["query"]})
        for c in state["classifications"]
    ]


def query_github(state: AgentInput) -> dict:
    """Query the GitHub agent."""
    result = github_agent.invoke({
        "messages": [{"role": "user", "content": state["query"]}]
    })
    return {"results": [{"source": "github", "result": result["messages"][-1].content}]}


def query_notion(state: AgentInput) -> dict:
    """Query the Notion agent."""
    result = notion_agent.invoke({
        "messages": [{"role": "user", "content": state["query"]}]
    })
    return {"results": [{"source": "notion", "result": result["messages"][-1].content}]}


def query_slack(state: AgentInput) -> dict:
    """Query the Slack agent."""
    result = slack_agent.invoke({
        "messages": [{"role": "user", "content": state["query"]}]
    })
    return {"results": [{"source": "slack", "result": result["messages"][-1].content}]}


def synthesize_results(state: RouterState) -> dict:
    """Combine results from all agents into a coherent answer."""
    if not state["results"]:
        return {"final_answer": "No results found from any knowledge source."}

    formatted = [
        f"**From {r['source'].title()}:**\n{r['result']}"
        for r in state["results"]
    ]

    synthesis_response = router_llm.invoke([
        {
            "role": "system",
            "content": f"""Synthesize these search results to answer the original question: "{state['query']}"

- Combine information from multiple sources without redundancy
- Highlight the most relevant and actionable information
- Note any discrepancies between sources
- Keep the response concise and well-organized"""
        },
        {"role": "user", "content": "\n\n".join(formatted)}
    ])

    return {"final_answer": synthesis_response.content}


# Build workflow
workflow = (
    StateGraph(RouterState)
    .add_node("classify", classify_query)
    .add_node("github", query_github)
    .add_node("notion", query_notion)
    .add_node("slack", query_slack)
    .add_node("synthesize", synthesize_results)
    .add_edge(START, "classify")
    .add_conditional_edges("classify", route_to_agents, ["github", "notion", "slack"])
    .add_edge("github", "synthesize")
    .add_edge("notion", "synthesize")
    .add_edge("slack", "synthesize")
    .add_edge("synthesize", END)
    .compile()
)

# if __name__ == "__main__":
#     result = workflow.invoke({
#         "query": "How do I authenticate API requests?"
#     })

#     print("Original query:", result["query"])
#     print("\nClassifications:")
#     for c in result["classifications"]:
#         print(f"  {c['source']}: {c['query']}")
#     print("\n" + "=" * 60 + "\n")
#     print("Final Answer:")
#     print(result["final_answer"])

if __name__ == "__main__":
    from rich.console import Console
    from rich.panel import Panel
    from rich.syntax import Syntax
    from rich.markdown import Markdown
    from rich import print as rprint
    
    console = Console()
    query = "How do I authenticate API requests?"
    
    console.print(f"\n[bold cyan]üîç Query:[/bold cyan] [italic]{query}[/italic]\n")
    
    # Stream the execution
    step_count = 0
    for step in workflow.stream({"query": query}):
        step_count += 1
        
        # Each step is a dict where keys are node names
        for node_name, node_output in step.items():
            # Node header with emoji based on node type
            node_emoji = {
                "classify": "üéØ",
                "github": "üíª",
                "notion": "üìù",
                "slack": "üí¨",
                "synthesize": "üîó"
            }.get(node_name, "‚öôÔ∏è")
            
            console.print(f"\n[bold yellow]{'‚îÄ' * 60}[/bold yellow]")
            console.print(f"[bold]{node_emoji} Step {step_count}: [magenta]{node_name.upper()}[/magenta][/bold]")
            console.print(f"[bold yellow]{'‚îÄ' * 60}[/bold yellow]")
            
            # Show what was updated in the state
            if "classifications" in node_output:
                console.print("\n[bold green]üìã Classifications:[/bold green]")
                for c in node_output["classifications"]:
                    console.print(f"  [cyan]‚Üí[/cyan] [yellow]{c['source']}:[/yellow] {c['query']}")
            
            if "results" in node_output:
                console.print("\n[bold green]‚úÖ Results:[/bold green]")
                for r in node_output["results"]:
                    result_preview = r['result']
                    console.print(Panel(
                        result_preview,
                        title=f"[bold cyan]{r['source'].upper()}[/bold cyan]",
                        border_style="blue",
                        padding=(0, 1)
                    ))
            
            if "final_answer" in node_output:
                console.print("\n[bold green]üéØ Final Answer:[/bold green]")
                console.print(Panel(
                    Markdown(node_output['final_answer']),
                    title="[bold green]Synthesized Response[/bold green]",
                    border_style="green",
                    padding=(1, 2)
                ))
    
    console.print(f"\n[bold cyan]{'‚îÄ' * 60}[/bold cyan]")
    console.print(f"[bold green]‚ú® Workflow completed in {step_count} steps[/bold green]")
    console.print(f"[bold cyan]{'‚îÄ' * 60}[/bold cyan]\n")